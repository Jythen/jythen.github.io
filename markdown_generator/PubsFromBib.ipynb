{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedCaseInsensitiveDict([('title', 'Bandits dueling on partially ordered sets'), ('booktitle', 'Advances in Neural Information Processing Systems'), ('keywords', 'enclosed, mypaper'), ('pages', '2129--2138'), ('year', '2017')])\n",
      "[Person('Audiffren, Julien'), Person('Ralaivola, Liva')]\n",
      "Audiffren, J. and Ralaivola, L.\n",
      "SUCESSFULLY PARSED : \" Bandits dueling on partially ordered sets  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Dichotomous Optimistic Search to Quantify Human Perception'), ('booktitle', 'International Conference on Machine Learning'), ('keywords', 'enclosed, mypaper'), ('pages', '414--424'), ('year', '2021'), ('organization', 'PMLR')])\n",
      "[Person('Audiffren, Julien')]\n",
      "Audiffren, J.\n",
      "SUCESSFULLY PARSED : \" Dichotomous Optimistic Search to Quantify Human Perception  \"\n",
      "OrderedCaseInsensitiveDict([('title', 'It’s not all in your feet: Improving penalty kick performance with human-avatar interaction and Machine Learning'), ('journal', 'The Innovation'), ('keywords', 'enclosed, mypaper'), ('year', '2024'), ('publisher', 'Elsevier')])\n",
      "[Person('Bloechle, Jean-Luc'), Person('Audiffren, Julien'), Person('Le Naour, Thibaut'), Person('Alli, Andrea'), Person('Simoni, Dylan'), Person('W{\\\\\"u}thrich, Gabriel'), Person('Bresciani, Jean-Pierre')]\n",
      "Bloechle, J., Audiffren, J., Le, T., Alli, A., Simoni, D., W{\\\"u}thrich, G. and Bresciani, J.\n",
      "SUCESSFULLY PARSED : \" It’s not all in your feet: Improving penalty kick performanc ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Operator-valued kernels for learning from functional response data'), ('journal', 'Journal of Machine Learning Research'), ('keywords', 'enclosed, mypaper'), ('volume', '17'), ('number', '20'), ('pages', '1--54'), ('year', '2016')])\n",
      "[Person('Kadri, Hachem'), Person('Duflos, Emmanuel'), Person('Preux, Philippe'), Person(\"Canu, St{\\\\'e}phane\"), Person('Rakotomamonjy, Alain'), Person('Audiffren, Julien')]\n",
      "Kadri, H., Duflos, E., Preux, P., Canu, S., Rakotomamonjy, A. and Audiffren, J.\n",
      "SUCESSFULLY PARSED : \" Operator-valued kernels for learning from functional respons ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Follow the Path: Hierarchy-Aware Extreme Multi-Label Completion for Semantic Text Tagging'), ('booktitle', 'Proceedings of the ACM on Web Conference 2024'), ('pages', '2094--2105'), ('keywords', 'enclosed, mypaper'), ('year', '2024')])\n",
      "[Person('Ostapuk, Natalia'), Person('Audiffren, Julien'), Person('Dolamic, Ljiljana'), Person('Mermoud, Alain'), Person(\"Cudr{\\\\'e}-Mauroux, Philippe\")]\n",
      "Ostapuk, N., Audiffren, J., Dolamic, L., Mermoud, A. and Cudr{\\'e}-Mauroux, P.\n",
      "SUCESSFULLY PARSED : \" Follow the Path: Hierarchy-Aware Extreme Multi-Label Complet ... \"\n",
      "OrderedCaseInsensitiveDict([('title', 'Do Large Language Models Exhibit Cognitive Dissonance? Studying the Difference Between Revealed Beliefs and Stated Answers'), ('type', 'preprint'), ('institution', '•'), ('year', '2024'), ('keywords', 'mypaper, enclosed'), ('OPTsubtitle', '•'), ('OPTtitleaddon', '•'), ('OPTlanguage', '•'), ('OPTnumber', '•'), ('OPTversion', '•'), ('OPTnote', '•'), ('OPTlocation', '•'), ('OPTmonth', '•'), ('OPTisrn', '•'), ('OPTchapter', '•'), ('OPTpages', '•'), ('OPTpagetotal', '•'), ('OPTaddendum', '•'), ('OPTpubstate', '•'), ('OPTdoi', '•'), ('OPTeprint', '•'), ('OPTeprintclass', '•'), ('OPTeprinttype', '•'), ('OPTurl', '•'), ('OPTurldate', '•')])\n",
      "[Person('Mondal, Manuel'), Person('Dolamic, Ljiljana'), Person('Bovet, Gérôme'), Person('Cudré-Mauroux, Philippe'), Person('Audiffren, Julien')]\n",
      "Mondal, M., Dolamic, L., Bovet, G., Cudré-Mauroux, P. and Audiffren, J.\n",
      "SUCESSFULLY PARSED : \" Do Large Language Models Exhibit Cognitive Dissonance? Study ... \"\n"
     ]
    }
   ],
   "source": [
    "parser = bibtex.Parser()\n",
    "bibdata = parser.parse_file(\"mypapers.bib\")\n",
    "for bib_id in bibdata.entries:\n",
    "    b = bibdata.entries[bib_id].fields\n",
    "    kw = b[\"keywords\"]\n",
    "    if \"enclosed\" in kw :\n",
    "\n",
    "        print(b)\n",
    "        \n",
    "        pub_year = pub_date = f'{b[\"year\"]}'\n",
    "\n",
    "        title = b[\"title\"]\n",
    "        clean_title = title.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")      \n",
    "        url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "        url_slug = url_slug.replace(\"--\",\"-\")\n",
    "        md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "        html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "\n",
    "        auth  =bibdata.entries[bib_id].persons[\"author\"]\n",
    "        authors = \"\"\n",
    "        print(auth)\n",
    "        for i in range(len(auth)):\n",
    "            p = auth[i]\n",
    "            conj = \", \"\n",
    "            if i == len(auth) -2 :\n",
    "                conj = \" and \"\n",
    "            elif i == len(auth) -1 :\n",
    "                conj = \"\"\n",
    "        \n",
    "            authors = authors+p.last_names[0]+\", \"+p.first_names[0][0]+\".\" + conj\n",
    "        print(authors)\n",
    "        authors = authors[1 : -2]\n",
    "\n",
    "        if 'booktitle' in b: venue = b[\"booktitle\"] \n",
    "        elif 'journal' in b : venue = b[\"journal\"]\n",
    "        else : venue = \"Preprint\"\n",
    "        date = pub_date\n",
    "        link = b[\"url\"]\n",
    "\n",
    "\n",
    "      \n",
    "        md = \"---\\ntitle: \\\"\"   + html_escape(title.replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "        md += \"\\nauthors: \" + str(authors) \n",
    "        md += \"\\nvenue: \" + str(venue) \n",
    "        md += \"\\ndate: \" + str(pub_date) \n",
    "        md += \"\\n[Access paper here] ('\" + link + \"')\"\n",
    "        md += \"\\n---\"\n",
    "\n",
    "        md_filename = os.path.basename(md_filename)\n",
    "\n",
    "        with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(md)\n",
    "        print(f'SUCESSFULLY PARSED : \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"proceeding\": {\n",
    "        \"file\" : \"proceedings.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "        \n",
    "    },\n",
    "    \"journal\":{\n",
    "        \"file\": \"pubs.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"}\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pubsource in publist:\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "\n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        \n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(\"../_publications/\" + md_filename, 'w', encoding=\"utf-8\") as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
